# This version of the YAML uses processed patches
project: /home/eytan/projects/medical_ssl_3d
run_name: "dinov2_pretrain_freezelastlayerfor1500steps_baselr0.001_warmupteacherfor15000steps_globalcrops0.8-0.1_patches16_epochs9000_batch6_maskingbug"
img_size: [128, 128, 128]
hidden_size: 180 # 864, 180
patch_size: [4, 4, 4] # [8, 8, 8], [4, 4, 4]

trainer:
  _target_: pytorch_lightning.Trainer
  benchmark: True
  max_epochs: 9000
  accelerator: gpu
  # strategy: ddp_find_unused_parameters_true
  enable_model_summary: False
  log_every_n_steps: 10
  limit_train_batches: 50
  fast_dev_run: False
  num_sanity_val_steps: 1
  check_val_every_n_epoch: 25
  precision: 16-mixed
  #  devices: 3
  detect_anomaly: False
  # sync_batchnorm: True
  logger:
    _target_: pytorch_lightning.loggers.WandbLogger
    project: "medical_ssl_3d"
    name: "@run_name"
    save_dir: "$'/home/eytan/storage/staff/eytankats/projects/medssl3d/experiments/' + @run_name + '/wandblogs'"
  callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      dirpath: "$'/home/eytan/storage/staff/eytankats/projects/medssl3d/experiments/' + @run_name + '/checkpoints'"
      filename: "best-{epoch:03d}-{val_dice:.4f}"
      monitor: 'val_dice'
      mode: 'max'
      save_top_k: 1
      save_last: True
      every_n_epochs: 5

lightning_module:
    _target_: project.training.lightning_module.DINOv2_3D_LightningModule
    batch_size_per_device: 6
    hidden_size: "%hidden_size"
    ibot_separate_head: True
    base_lr: 0.001
    layer_decay: 0.9
    gradient_clip_val: 3.0
    teacher_temp_warmup_epochs: 300
    teacher_temp_min: 0.04
    teacher_temp_max: 0.055  # 0.07
    momentum_start_value: 0.992
    momentum_end_value: 1.0
    freeze_last_layer_epochs: 0  # 30
    projection_dim: 8192 # 65536
    ibot_projection_dim: 8192 # 65536
    mask_ratio_min: 0.4
    mask_ratio_max: 0.7
    sampling: 'entropy'
    weight_decay: 0.04
    apply_gin: False
    ckpt_path: "/home/eytan/storage/staff/eytankats/projects/medssl3d/experiments/patch_4/checkpoints/model_epoch=1534.ckpt"
    output_dir: "$'/home/eytan/storage/staff/eytankats/projects/medssl3d/experiments/' + @run_name + '/val_artifacts'"
    backbone:

data_module:
  _target_: project.training.data_module.DataModule
  num_workers: 12
  batch_size: 6
  pin_memory: True
  drop_last: True
  train_dataset:
    _target_: project.utils.safe_dataset.SafeDataset # Dataset that reshuffles erroneous data! Use carefully as it might skip data 
    dataset:
      _target_: monai.data.Dataset
      data:
      transform:
          _target_: torchvision.transforms.Compose
          transforms:
            - _target_: monai.transforms.LoadImaged
              keys: ["image"]
              image_only: True
            - _target_: monai.transforms.EnsureChannelFirstd
              keys: ["image"]
            - _target_: monai.transforms.ScaleIntensityRangePercentilesd
              keys: ["image"]
              lower: 1
              upper: 99
              b_min: 0.0
              b_max: 1.0
              clip: True
            - _target_: torchvision.transforms.Lambda
              lambd: "$lambda x: x['image'].as_tensor()"
            - _target_: project.transforms.dinov2_aug.DINOv2Augmentation3D
              global_view_scale: [0.8, 1.0]
              global_view_size: "$@img_size[0]"
              local_view_scale: [0.3, 1.0]
              local_view_size: "$@img_size[0]//2"
              num_local_views: 0 # No local views for now, we need to add suport for interpolated position embeddings
            - _target_: torchvision.transforms.Lambda
              lambd: "$lambda x: (x, False)" # Incase you need labels.
  val_dataset:
    _target_: project.utils.safe_dataset.SafeDataset # Dataset that reshuffles erroneous data! Use carefully as it might skip data
    dataset:
      _target_: monai.data.Dataset
      data:
      transform:
        _target_: torchvision.transforms.Compose
        transforms:
          - _target_: monai.transforms.LoadImaged
            keys: [ "fixed", "moving" , "label_fixed", "label_moving"]
            image_only: True
          - _target_: monai.transforms.EnsureChannelFirstd
            keys: [ "fixed", "moving" , "label_fixed", "label_moving"]
          - _target_: monai.transforms.ScaleIntensityRangePercentilesd
            keys: [ "fixed", "moving" ]
            lower: 1
            upper: 99
            b_min: 0.0
            b_max: 1.0
            clip: True
          - _target_: torchvision.transforms.Lambda
            lambd: "$lambda x: [x['fixed'].as_tensor(), x['moving'].as_tensor(), x['label_fixed'].as_tensor(), x['label_moving'].as_tensor()]"